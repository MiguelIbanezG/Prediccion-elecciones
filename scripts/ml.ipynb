{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba78fd5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Librerías ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412b32b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Montar Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Ruta al CSV ---\n",
    "dataset = '/content/drive/MyDrive/FINAL_DB.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75814d26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Configuración ---\n",
    "dataset = '/content/drive/MyDrive/FINAL_DB.csv'\n",
    "label = 'Candidatura Ganadora'\n",
    "hot = ['Mesa', 'Comunidad', 'Provincia', 'Gobierno Actual de Comunidad', 'Gobierno Actual de España']\n",
    "norm = ['Edad Media', 'Escolarizacion', 'Esperanza de Vida', 'Habitantes Provincia',\n",
    "        'Acceso a Internet', 'PIB per capita', 'Criminalidad', 'Inmigracion',\n",
    "        '% de mujeres', 'Tasa de Pobreza', 'Tasa Desempleo']\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "momentum = 0\n",
    "test_ratio = 0.30\n",
    "metricas = ['accuracy']\n",
    "inicializacion_pesos = ['glorot_normal', 'glorot_normal']\n",
    "batch = 32\n",
    "activation_layer_1 = 'relu'\n",
    "nneurons_layer_1 = 32\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizador = 'adam'\n",
    "tf.random.set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07892641",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Cargar y preprocesar datos ---\n",
    "def carga_datos_csv(data, categoria, porcentaje_test=0.25, hot_encoded=None, normalizados=None, seed=None):\n",
    "    # Normalización\n",
    "    for col in normalizados:\n",
    "        if col in data.columns:\n",
    "            data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "    # Eliminar filas con NaN en cualquier columna\n",
    "    data = data.dropna()\n",
    "\n",
    "    # División train/test\n",
    "    train, test = train_test_split(data, test_size=porcentaje_test, random_state=seed)\n",
    "\n",
    "    # Separar etiquetas\n",
    "    label_train = train[categoria].copy()\n",
    "    label_test = test[categoria].copy()\n",
    "    train = train.drop(columns=[categoria])\n",
    "    test = test.drop(columns=[categoria])\n",
    "\n",
    "    # One-hot encoding\n",
    "    if hot_encoded:\n",
    "        full_data = pd.concat([train, test])\n",
    "        full_data = pd.get_dummies(full_data, columns=hot_encoded)\n",
    "        train = full_data.iloc[:len(train), :]\n",
    "        test = full_data.iloc[len(train):, :]\n",
    "\n",
    "    test = test.reindex(columns=train.columns, fill_value=0)\n",
    "\n",
    "    # Codificar etiquetas como one-hot\n",
    "    label_train = pd.get_dummies(label_train)\n",
    "    label_test = pd.get_dummies(label_test)\n",
    "\n",
    "    # Alinear etiquetas\n",
    "    label_test = label_test.reindex(columns=label_train.columns, fill_value=0)\n",
    "\n",
    "    return (\n",
    "    train.columns,\n",
    "    label_train.columns,\n",
    "    train.to_numpy().astype(np.float32),\n",
    "    label_train.to_numpy().astype(np.float32),\n",
    "    test.to_numpy().astype(np.float32),\n",
    "    label_test.to_numpy().astype(np.float32)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac77d27",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar CSV\n",
    "data = pd.read_csv(dataset, sep=',')\n",
    "data = data.dropna(subset=[label])  # Asegurar que la columna de salida existe\n",
    "\n",
    "x_columns, y_columns, x_train, y_train, x_test, y_test = carga_datos_csv(\n",
    "    data, label, porcentaje_test=test_ratio, hot_encoded=hot, normalizados=norm, seed=int(datetime.utcnow().timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855a167",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Crear modelo ---\n",
    "model = Sequential([\n",
    "    Dense(len(x_train[0]), input_shape=(len(x_train[0]),)),  # Capa de entrada\n",
    "    Dense(nneurons_layer_1, activation=activation_layer_1, kernel_initializer=inicializacion_pesos[0]),  # Capa oculta\n",
    "    Dense(len(y_train[0]), activation='softmax', kernel_initializer=inicializacion_pesos[1])  # Capa de salida\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizador, loss=loss, metrics=metricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2b952",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " #--- Entrenamiento ---\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d4b81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Evaluación ---\n",
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bf2c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Predicción (convertimos una-hot a clase) ---\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# --- Nombres de clases ---\n",
    "class_names = y_columns  # ya están alineadas\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# --- Informe de clasificación ---\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names, zero_division=0))\n",
    "\n",
    "# --- Visualización ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Matriz de Confusión - Red Neuronal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
