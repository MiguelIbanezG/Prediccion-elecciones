{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443b696",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Librerías ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "from google.colab import drive\n",
    "\n",
    "# Semilla global\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba1530",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Montar Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Ruta al CSV ---\n",
    "dataset = '/content/drive/MyDrive/FINAL_DB.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fdbf1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Configuración ---\n",
    "dataset = '/content/drive/MyDrive/FINAL_DB.csv'\n",
    "label = 'Candidatura Ganadora'\n",
    "hot = ['Mesa', 'Comunidad', 'Provincia', 'Gobierno Actual de Comunidad', 'Gobierno Actual de España']\n",
    "norm = ['Edad Media', 'Escolarizacion', 'Esperanza de Vida', 'Habitantes Provincia',\n",
    "        'Acceso a Internet', 'PIB per capita', 'Criminalidad', 'Inmigracion',\n",
    "        '% de mujeres', 'Tasa de Pobreza', 'Tasa Desempleo']\n",
    "epochs = 10\n",
    "lr = 0.1\n",
    "momentum = 0\n",
    "test_ratio = 0.30\n",
    "metricas = ['accuracy']\n",
    "inicializacion_pesos = 'glorot_normal'\n",
    "batch = 32\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizador = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7016d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Función de carga y preprocesamiento ---\n",
    "def carga_datos_csv(data, categoria, porcentaje_test=0.25, hot_encoded=None, normalizados=None, seed=None):\n",
    "    # Normalización\n",
    "    for col in normalizados:\n",
    "        if col in data.columns:\n",
    "            data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "    # Eliminar filas con NaN\n",
    "    data = data.dropna()\n",
    "\n",
    "    # División train/test\n",
    "    train, test = train_test_split(data, test_size=porcentaje_test, random_state=seed)\n",
    "\n",
    "    # Separar etiquetas\n",
    "    label_train = train[categoria].copy()\n",
    "    label_test = test[categoria].copy()\n",
    "    train = train.drop(columns=[categoria])\n",
    "    test = test.drop(columns=[categoria])\n",
    "\n",
    "    # One-hot encoding de entradas\n",
    "    if hot_encoded:\n",
    "        full = pd.concat([train, test])\n",
    "        full = pd.get_dummies(full, columns=hot_encoded)\n",
    "        train = full.iloc[:len(train)]\n",
    "        test = full.iloc[len(train):]\n",
    "\n",
    "    # Alinear columnas\n",
    "    test = test.reindex(columns=train.columns, fill_value=0)\n",
    "\n",
    "    # One-hot encoding de etiquetas\n",
    "    label_train = pd.get_dummies(label_train)\n",
    "    label_test = pd.get_dummies(label_test)\n",
    "\n",
    "    # Alinear columnas de salida\n",
    "    label_test = label_test.reindex(columns=label_train.columns, fill_value=0)\n",
    "\n",
    "    return (train.columns, label_train.columns), (\n",
    "        train.to_numpy().astype(np.float32),\n",
    "        label_train.to_numpy().astype(np.float32),\n",
    "        test.to_numpy().astype(np.float32),\n",
    "        label_test.to_numpy().astype(np.float32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4640d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Carga de datos ---\n",
    "data = pd.read_csv(dataset, sep=',')\n",
    "data = data.dropna(subset=[label])\n",
    "\n",
    "(x_columns, y_columns), (x_train, y_train, x_test, y_test)= carga_datos_csv(\n",
    "    data, label, porcentaje_test=test_ratio, hot_encoded=hot, normalizados=norm, seed=int(datetime.utcnow().timestamp())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c08d87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Red neuronal ---\n",
    "model = Sequential([\n",
    "    Dense(len(x_train[0]), input_shape=(len(x_train[0]),)),\n",
    "    Dense(len(y_train[0]), activation='softmax', kernel_initializer=inicializacion_pesos)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizador, loss=loss, metrics=metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572d91b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Entrenamiento ---\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecea5e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluación ---\n",
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cfad0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Predicción ---\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# --- Nombres de clases ---\n",
    "class_names = y_columns\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# --- Informe de clasificación ---\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names, zero_division=0))\n",
    "\n",
    "# --- Visualización de la matriz ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Matriz de Confusión - Red Neuronal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
